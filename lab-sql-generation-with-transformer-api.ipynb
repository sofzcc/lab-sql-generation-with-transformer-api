{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sofzcc/lab-sql-generation-with-transformer-api/blob/main/lab-sql-generation-with-transformer-api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrf8A9N9_qwC"
      },
      "source": [
        "# SQL Generation with Transformer API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8bAMjQKJfG3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b10bcfb3-a25f-44dc-af3a-49b42f4bfa90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers bitsandbytes accelerate sqlparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BzllQomZfQnj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hztT0MXkfRs1",
        "outputId": "1c4ebe3c-7d8d-4c50-daa9-85984b7cc7b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7jsl838clW_f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "bd201c36-0a17-49a8-c5ed-d22ff7d6a614"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8de129f23d37>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mavailable_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0m_CudaDeviceProperties\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproperties\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \"\"\"\n\u001b[0;32m--> 444\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# will define _get_device_properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "available_memory = torch.cuda.get_device_properties(0).total_memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTQnCfsen16q"
      },
      "outputs": [],
      "source": [
        "print(available_memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt4ilTkpTMoL"
      },
      "source": [
        "##Download the Model\n",
        "Use any model on Colab (or any system with >30GB VRAM on your own machine) to load this in f16. If unavailable, use a GPU with minimum 8GB VRAM to load this in 8bit, or with minimum 5GB of VRAM to load in 4bit.\n",
        "\n",
        "This step can take around 5 minutes the first time. So please be patient :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "f5c784d080a04837baedb19e45960e2e",
            "0ddfaacac875440d99e923c9aa9c2ec2",
            "0e7432e11c104365bf6edfe5a242c901",
            "8ad5cd204f944b77984bc95b1f7f60a2",
            "8dfccf42b60440169daba773cbbfa97c",
            "2a2e9dd3fa184613a6071456ff2a6d83",
            "a86885e0908b4338a78f3f663d5066c2",
            "723b6821c72a41b5a92544d88cfb37e9",
            "9161b0c8dadd48d3a39d15d2cade04bc",
            "a153d269e2e4496cace8617963d7780c",
            "5138e9f2fa7041bd8e39f8beca882f52"
          ]
        },
        "id": "_mNT25UOfSMw",
        "outputId": "a8b1c74d-9ca1-4163-d679-ce3b76efc0f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5c784d080a04837baedb19e45960e2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu and disk.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"defog/sqlcoder-7b-2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#if available_memory > 15e9:\n",
        "    # if you have atleast 15GB of GPU memory, run load the model in float16\n",
        " #   model = AutoModelForCausalLM.from_pretrained(\n",
        "  #      model_name,\n",
        "    #    trust_remote_code=True,\n",
        "     #   torch_dtype=torch.float16,\n",
        "      #  device_map=\"auto\",\n",
        "       # use_cache=True,\n",
        "  #  )\n",
        "#else:\n",
        "    # else, load in 8 bits – this is a bit slower\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        trust_remote_code=True,\n",
        "        # torch_dtype=torch.float16,\n",
        "        #load_in_8bit=True,\n",
        "        device_map=\"auto\",\n",
        "        use_cache=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzLcpXyzTkHM"
      },
      "source": [
        "##Set the Question & Prompt and Tokenize\n",
        "Feel free to change the schema in the prompt below to your own schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0eI-VpCkf-fN"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"### Task\n",
        "Generate a SQL query to answer [QUESTION]{question}[/QUESTION]\n",
        "\n",
        "### Instructions\n",
        "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
        "- Remember that revenue is price multiplied by quantity\n",
        "- Remember that cost is supply_price multiplied by quantity\n",
        "\n",
        "### Database Schema\n",
        "This query will run on a database whose schema is represented in this string:\n",
        "CREATE TABLE products (\n",
        "  product_id INTEGER PRIMARY KEY, -- Unique ID for each product\n",
        "  name VARCHAR(50), -- Name of the product\n",
        "  price DECIMAL(10,2), -- Price of each unit of the product\n",
        "  quantity INTEGER  -- Current quantity in stock\n",
        ");\n",
        "\n",
        "CREATE TABLE customers (\n",
        "   customer_id INTEGER PRIMARY KEY, -- Unique ID for each customer\n",
        "   name VARCHAR(50), -- Name of the customer\n",
        "   address VARCHAR(100) -- Mailing address of the customer\n",
        ");\n",
        "\n",
        "CREATE TABLE salespeople (\n",
        "  salesperson_id INTEGER PRIMARY KEY, -- Unique ID for each salesperson\n",
        "  name VARCHAR(50), -- Name of the salesperson\n",
        "  region VARCHAR(50) -- Geographic sales region\n",
        ");\n",
        "\n",
        "CREATE TABLE sales (\n",
        "  sale_id INTEGER PRIMARY KEY, -- Unique ID for each sale\n",
        "  product_id INTEGER, -- ID of product sold\n",
        "  customer_id INTEGER,  -- ID of customer who made purchase\n",
        "  salesperson_id INTEGER, -- ID of salesperson who made the sale\n",
        "  sale_date DATE, -- Date the sale occurred\n",
        "  quantity INTEGER -- Quantity of product sold\n",
        ");\n",
        "\n",
        "CREATE TABLE product_suppliers (\n",
        "  supplier_id INTEGER PRIMARY KEY, -- Unique ID for each supplier\n",
        "  product_id INTEGER, -- Product ID supplied\n",
        "  supply_price DECIMAL(10,2) -- Unit price charged by supplier\n",
        ");\n",
        "\n",
        "-- sales.product_id can be joined with products.product_id\n",
        "-- sales.customer_id can be joined with customers.customer_id\n",
        "-- sales.salesperson_id can be joined with salespeople.salesperson_id\n",
        "-- product_suppliers.product_id can be joined with products.product_id\n",
        "\n",
        "### Answer\n",
        "Given the database schema, here is the SQL query that answers [QUESTION]{question}[/QUESTION]\n",
        "[SQL]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2Lyi9VcVoTA"
      },
      "source": [
        "##Generate the SQL\n",
        "This can be excruciatingly slow on a T4 in Colab, and can take 10-20 seconds per query. On faster GPUs, this will take ~1-2 seconds\n",
        "\n",
        "Ideally, you should use `num_beams`=4 for best results. But because of memory constraints, we will stick to just 1 for now."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Original**"
      ],
      "metadata": {
        "id": "_EVCCMP42UdQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4iBKg6Rmmpnw"
      },
      "outputs": [],
      "source": [
        "import sqlparse\n",
        "\n",
        "def generate_query(question):\n",
        "    updated_prompt = prompt.format(question=question)\n",
        "    inputs = tokenizer(updated_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    generated_ids = model.generate(\n",
        "        **inputs,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        max_new_tokens=400,\n",
        "        do_sample=False,\n",
        "        num_beams=1,\n",
        "    )\n",
        "    outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "    # empty cache so that you do generate more results w/o memory crashing\n",
        "    # particularly important on Colab – memory management is much more straightforward\n",
        "    # when running on an inference service\n",
        "    return sqlparse.format(outputs[0].split(\"[SQL]\")[-1], reindent=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NSFZo_RpuSvF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCJvcurqlP2_"
      },
      "outputs": [],
      "source": [
        "question = \"What was our revenue by product in the New York region last month?\"\n",
        "generated_sql = generate_query(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flEJuo1OpYQ8"
      },
      "outputs": [],
      "source": [
        "print(generated_sql)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09ysYJbsnKUh"
      },
      "source": [
        "# Exercise\n",
        " - Complete the prompts similar to what we did in class.\n",
        "     - Try at least 3 versions\n",
        "     - Be creative\n",
        " - Write a one page report summarizing your findings.\n",
        "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
        " - What did you learn?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TsknMK__qwU",
        "outputId": "f30343c5-6ed7-4e73-d3c1-afe3813d9091"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variation 1**"
      ],
      "metadata": {
        "id": "of1vQHICoJlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_1 = \"\"\"### Task\n",
        "Generate a SQL query to calculate total sales revenue by product category.\n",
        "\n",
        "### Instructions\n",
        "- Use the provided database schema to construct the query.\n",
        "- Ensure the query calculates revenue based on sales quantity and product price.\n",
        "\n",
        "\n",
        "### Database Schema\n",
        "This query will run on a database whose schema is represented in this string:\n",
        "CREATE TABLE products (\n",
        "  product_id INTEGER PRIMARY KEY, -- Unique ID for each product\n",
        "  name VARCHAR(50), -- Name of the product\n",
        "  price DECIMAL(10,2), -- Price of each unit of the product\n",
        "  quantity INTEGER  -- Current quantity in stock\n",
        ");\n",
        "\n",
        "CREATE TABLE customers (\n",
        "   customer_id INTEGER PRIMARY KEY, -- Unique ID for each customer\n",
        "   name VARCHAR(50), -- Name of the customer\n",
        "   address VARCHAR(100) -- Mailing address of the customer\n",
        ");\n",
        "\n",
        "CREATE TABLE salespeople (\n",
        "  salesperson_id INTEGER PRIMARY KEY, -- Unique ID for each salesperson\n",
        "  name VARCHAR(50), -- Name of the salesperson\n",
        "  region VARCHAR(50) -- Geographic sales region\n",
        ");\n",
        "\n",
        "CREATE TABLE sales (\n",
        "  sale_id INTEGER PRIMARY KEY, -- Unique ID for each sale\n",
        "  product_id INTEGER, -- ID of product sold\n",
        "  customer_id INTEGER,  -- ID of customer who made purchase\n",
        "  salesperson_id INTEGER, -- ID of salesperson who made the sale\n",
        "  sale_date DATE, -- Date the sale occurred\n",
        "  quantity INTEGER -- Quantity of product sold\n",
        ");\n",
        "\n",
        "CREATE TABLE product_suppliers (\n",
        "  supplier_id INTEGER PRIMARY KEY, -- Unique ID for each supplier\n",
        "  product_id INTEGER, -- Product ID supplied\n",
        "  supply_price DECIMAL(10,2) -- Unit price charged by supplier\n",
        ");\n",
        "\n",
        "-- sales.product_id can be joined with products.product_id\n",
        "-- sales.customer_id can be joined with customers.customer_id\n",
        "-- sales.salesperson_id can be joined with salespeople.salesperson_id\n",
        "-- product_suppliers.product_id can be joined with products.product_id\n",
        "\n",
        "### Answer\n",
        "Given the database schema, here is the SQL query that answers the question.\n",
        "[SQL]\"\"\"\n"
      ],
      "metadata": {
        "id": "jddihdxqoLy5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What was our revenue by product in the New York region last month?\"\n",
        "generated_sql = generate_query(question, prompt_1)"
      ],
      "metadata": {
        "id": "wtD4iHTfxg0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Different Schema**"
      ],
      "metadata": {
        "id": "EN3jvAyry9AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2 = \"\"\"### Task\n",
        "Generate a SQL query to answer [QUESTION]{question}[/QUESTION]\n",
        "\n",
        "### Instructions\n",
        "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
        "- Remember that revenue is price multiplied by quantity\n",
        "- Remember that cost is supply_price multiplied by quantity\n",
        "\n",
        "### Database Schema\n",
        "This query will run on a database whose schema is represented in this string:\n",
        "CREATE TABLE marvel_superheroes (\n",
        "  hero_id INTEGER PRIMARY KEY, -- Unique ID for each superhero\n",
        "  name VARCHAR(50), -- Name of the superhero\n",
        "  alias VARCHAR(50), -- Superhero alias or code name\n",
        "  power VARCHAR(100), -- Superpower possessed by the superhero\n",
        "  city VARCHAR(50), -- City where the superhero operates\n",
        "  date_of_birth DATE, -- Birthdate of the superhero\n",
        "  status VARCHAR(20) -- Status of the superhero (active, retired, etc.)\n",
        ");\n",
        "\n",
        "CREATE TABLE marvel_villains (\n",
        "  villain_id INTEGER PRIMARY KEY, -- Unique ID for each villain\n",
        "  name VARCHAR(50), -- Name of the villain\n",
        "  alias VARCHAR(50), -- Villain alias or code name\n",
        "  power VARCHAR(100), -- Special abilities possessed by the villain\n",
        "  nemesis VARCHAR(50) -- Arch-nemesis of the villain\n",
        ");\n",
        "\n",
        "CREATE TABLE marvel_battles (\n",
        "  battle_id INTEGER PRIMARY KEY, -- Unique ID for each battle\n",
        "  hero_id INTEGER, -- ID of the superhero involved\n",
        "  villain_id INTEGER, -- ID of the villain involved\n",
        "  location VARCHAR(50), -- Location where the battle took place\n",
        "  date DATE, -- Date when the battle occurred\n",
        "  outcome VARCHAR(20) -- Outcome of the battle (win, loss, draw)\n",
        ");\n",
        "\n",
        "CREATE TABLE marvel_hero_stats (\n",
        "  hero_id INTEGER PRIMARY KEY, -- Unique ID for each superhero\n",
        "  strength INTEGER, -- Strength level of the superhero\n",
        "  agility INTEGER, -- Agility level of the superhero\n",
        "  intelligence INTEGER -- Intelligence level of the superhero\n",
        ");\n",
        "\n",
        "CREATE TABLE marvel_villain_stats (\n",
        "  villain_id INTEGER PRIMARY KEY, -- Unique ID for each villain\n",
        "  strength INTEGER, -- Strength level of the villain\n",
        "  agility INTEGER, -- Agility level of the villain\n",
        "  intelligence INTEGER -- Intelligence level of the villain\n",
        ");\n",
        "\n",
        "-- marvel_battles.hero_id can be joined with marvel_superheroes.hero_id\n",
        "-- marvel_battles.villain_id can be joined with marvel_villains.villain_id\n",
        "-- marvel_hero_stats.hero_id can be joined with marvel_superheroes.hero_id\n",
        "-- marvel_villain_stats.villain_id can be joined with marvel_villains.villain_id\n",
        "\n",
        "### Answer\n",
        "Given the database schema, here is the SQL query that answers [QUESTION]{question}[/QUESTION]\n",
        "[SQL]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "FIiOiM0izARe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_query(question, prompt):\n",
        "    updated_prompt = prompt.format(question=question)\n",
        "\n",
        "    # Tokenize the prompt\n",
        "    inputs = tokenizer(updated_prompt, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate sequence on CPU\n",
        "    generated_ids = model.generate(\n",
        "        **inputs,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        max_new_tokens=400,\n",
        "        do_sample=False,\n",
        "        num_beams=1,\n",
        "    )\n",
        "\n",
        "    # Decode the generated sequence\n",
        "    outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Format and return the SQL query\n",
        "    return sqlparse.format(outputs[0].split(\"[SQL]\")[-1], reindent=True)\n"
      ],
      "metadata": {
        "id": "YLgbYsbD2aZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For loop to generate SQL queries\n",
        "\n",
        "questions = [\n",
        "    \"What is Iron Man's alias?\",\n",
        "    \"Who is Spider-Man's arch-nemesis?\",\n",
        "    \"List all battles involving Captain America.\",\n",
        "    \"Which superhero has the highest strength?\",\n",
        "    \"Which villain has the lowest intelligence?\",\n",
        "]\n",
        "\n",
        "# Loop through each question and generate the corresponding SQL query\n",
        "for question in questions:\n",
        "    generated_sql = generate_query(question, prompt_2)\n",
        "    formatted_sql = sqlparse.format(generated_sql, reindent=True)\n",
        "\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Generated SQL Query:\\n{formatted_sql}\\n\")\n"
      ],
      "metadata": {
        "id": "ZWwho1eLzfwa",
        "outputId": "c540e9c7-cef4-43ce-c6f1-bfba0bfe0844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'generate_query' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f2607f754d28>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Loop through each question and generate the corresponding SQL query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mgenerated_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mformatted_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_sql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generate_query' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusions** There isn't much to conclude as I can't run the original notebook. I need to wait until Colab allows me GPU access again."
      ],
      "metadata": {
        "id": "QOhj7KHe1IMy"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f5c784d080a04837baedb19e45960e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ddfaacac875440d99e923c9aa9c2ec2",
              "IPY_MODEL_0e7432e11c104365bf6edfe5a242c901",
              "IPY_MODEL_8ad5cd204f944b77984bc95b1f7f60a2"
            ],
            "layout": "IPY_MODEL_8dfccf42b60440169daba773cbbfa97c"
          }
        },
        "0ddfaacac875440d99e923c9aa9c2ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a2e9dd3fa184613a6071456ff2a6d83",
            "placeholder": "​",
            "style": "IPY_MODEL_a86885e0908b4338a78f3f663d5066c2",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0e7432e11c104365bf6edfe5a242c901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_723b6821c72a41b5a92544d88cfb37e9",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9161b0c8dadd48d3a39d15d2cade04bc",
            "value": 3
          }
        },
        "8ad5cd204f944b77984bc95b1f7f60a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a153d269e2e4496cace8617963d7780c",
            "placeholder": "​",
            "style": "IPY_MODEL_5138e9f2fa7041bd8e39f8beca882f52",
            "value": " 3/3 [00:58&lt;00:00, 29.16s/it]"
          }
        },
        "8dfccf42b60440169daba773cbbfa97c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a2e9dd3fa184613a6071456ff2a6d83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a86885e0908b4338a78f3f663d5066c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "723b6821c72a41b5a92544d88cfb37e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9161b0c8dadd48d3a39d15d2cade04bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a153d269e2e4496cace8617963d7780c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5138e9f2fa7041bd8e39f8beca882f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}